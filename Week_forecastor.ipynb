{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn\n",
    "# %pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date &amp; Time</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>SKU Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Item Value</th>\n",
       "      <th>Delivery Pincode</th>\n",
       "      <th>Payment Type</th>\n",
       "      <th>SKU_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-28 07:34:26</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>MuscleBlaze Limited Edition Shubman Shaker,  B...</td>\n",
       "      <td>1</td>\n",
       "      <td>699.0</td>\n",
       "      <td>201306</td>\n",
       "      <td>PREPAID</td>\n",
       "      <td>MuscleBlaze Limited Edition Shubman Shaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-28 07:34:26</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>MuscleBlaze High Protein Muesli,  0.4 kg  Dark...</td>\n",
       "      <td>1</td>\n",
       "      <td>399.0</td>\n",
       "      <td>201309</td>\n",
       "      <td>COD</td>\n",
       "      <td>MuscleBlaze High Protein Muesli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-28 07:34:27</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>MuscleBlaze High Protein Gold Gainer,  2.2 lb ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>201301</td>\n",
       "      <td>PREPAID</td>\n",
       "      <td>MuscleBlaze High Protein Gold Gainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-28 07:34:27</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>HK Vitals ProteinUp Active Strength &amp; Energy b...</td>\n",
       "      <td>1</td>\n",
       "      <td>799.0</td>\n",
       "      <td>201303</td>\n",
       "      <td>PREPAID</td>\n",
       "      <td>HK Vitals ProteinUp Active Strength &amp; Energy b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-28 07:34:28</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>MuscleBlaze Biozyme Performance Whey,  4.4 lb ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>201301</td>\n",
       "      <td>PREPAID</td>\n",
       "      <td>MuscleBlaze Biozyme Performance Whey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104421</th>\n",
       "      <td>2024-10-28 14:52:06</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>Supermilk Height+Â for Boy/Girl 4 to 7 years, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>110092</td>\n",
       "      <td>PREPAID</td>\n",
       "      <td>Supermilk Height+Â for Boy/Girl 4 to 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104422</th>\n",
       "      <td>2024-10-28 14:57:39</td>\n",
       "      <td>HEALTHKART</td>\n",
       "      <td>HealthKart HK Vitals Skin Radiance Collagen,  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>201304</td>\n",
       "      <td>COD</td>\n",
       "      <td>HealthKart HK Vitals Skin Radiance Collagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104423</th>\n",
       "      <td>2024-10-28 15:06:14</td>\n",
       "      <td>healthkart</td>\n",
       "      <td>MuscleBlaze T-Surge Black,  90 tablet(s)  Unfl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>121005</td>\n",
       "      <td>COD</td>\n",
       "      <td>MuscleBlaze T-Surge Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104424</th>\n",
       "      <td>2024-10-28 15:10:41</td>\n",
       "      <td>healthkart</td>\n",
       "      <td>HealthKart HK Vitals Skin Radiance Collagen,  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>110081</td>\n",
       "      <td>COD</td>\n",
       "      <td>HealthKart HK Vitals Skin Radiance Collagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104425</th>\n",
       "      <td>2024-10-28 15:22:19</td>\n",
       "      <td>healthkart</td>\n",
       "      <td>MuscleBlaze Shaker (Unleash the Zidd),  Yellow...</td>\n",
       "      <td>1</td>\n",
       "      <td>699.0</td>\n",
       "      <td>201306</td>\n",
       "      <td>COD</td>\n",
       "      <td>MuscleBlaze Shaker (Unleash the Zidd)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104426 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order Date & Time  Brand Name  \\\n",
       "0      2023-10-28 07:34:26  HEALTHKART   \n",
       "1      2023-10-28 07:34:26  HEALTHKART   \n",
       "2      2023-10-28 07:34:27  HEALTHKART   \n",
       "3      2023-10-28 07:34:27  HEALTHKART   \n",
       "4      2023-10-28 07:34:28  HEALTHKART   \n",
       "...                    ...         ...   \n",
       "104421 2024-10-28 14:52:06  HEALTHKART   \n",
       "104422 2024-10-28 14:57:39  HEALTHKART   \n",
       "104423 2024-10-28 15:06:14  healthkart   \n",
       "104424 2024-10-28 15:10:41  healthkart   \n",
       "104425 2024-10-28 15:22:19  healthkart   \n",
       "\n",
       "                                                 SKU Name  Quantity  \\\n",
       "0       MuscleBlaze Limited Edition Shubman Shaker,  B...         1   \n",
       "1       MuscleBlaze High Protein Muesli,  0.4 kg  Dark...         1   \n",
       "2       MuscleBlaze High Protein Gold Gainer,  2.2 lb ...         1   \n",
       "3       HK Vitals ProteinUp Active Strength & Energy b...         1   \n",
       "4       MuscleBlaze Biozyme Performance Whey,  4.4 lb ...         1   \n",
       "...                                                   ...       ...   \n",
       "104421  Supermilk Height+Â for Boy/Girl 4 to 7 years, ...         1   \n",
       "104422  HealthKart HK Vitals Skin Radiance Collagen,  ...         1   \n",
       "104423  MuscleBlaze T-Surge Black,  90 tablet(s)  Unfl...         1   \n",
       "104424  HealthKart HK Vitals Skin Radiance Collagen,  ...         1   \n",
       "104425  MuscleBlaze Shaker (Unleash the Zidd),  Yellow...         1   \n",
       "\n",
       "        Item Value  Delivery Pincode Payment Type  \\\n",
       "0            699.0            201306      PREPAID   \n",
       "1            399.0            201309          COD   \n",
       "2           2129.0            201301      PREPAID   \n",
       "3            799.0            201303      PREPAID   \n",
       "4           5499.0            201301      PREPAID   \n",
       "...            ...               ...          ...   \n",
       "104421      1348.0            110092      PREPAID   \n",
       "104422      1748.0            201304          COD   \n",
       "104423      1399.0            121005          COD   \n",
       "104424      1099.0            110081          COD   \n",
       "104425       699.0            201306          COD   \n",
       "\n",
       "                                              SKU_grouped  \n",
       "0              MuscleBlaze Limited Edition Shubman Shaker  \n",
       "1                         MuscleBlaze High Protein Muesli  \n",
       "2                    MuscleBlaze High Protein Gold Gainer  \n",
       "3       HK Vitals ProteinUp Active Strength & Energy b...  \n",
       "4                    MuscleBlaze Biozyme Performance Whey  \n",
       "...                                                   ...  \n",
       "104421       Supermilk Height+Â for Boy/Girl 4 to 7 years  \n",
       "104422        HealthKart HK Vitals Skin Radiance Collagen  \n",
       "104423                          MuscleBlaze T-Surge Black  \n",
       "104424        HealthKart HK Vitals Skin Radiance Collagen  \n",
       "104425              MuscleBlaze Shaker (Unleash the Zidd)  \n",
       "\n",
       "[104426 rows x 8 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_file=\"../../Data/brand details last 1 year.xlsx\"\n",
    "sales_data=pd.read_excel(sales_file,sheet_name='Healthkart')\n",
    "sales_data['SKU_grouped']=sales_data['SKU Name'].str.split(',',expand=True)[0]\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['SKU Name']=sales_data['SKU Name'].str.split('_')\n",
    "sales_data=sales_data.explode('SKU Name',ignore_index=True)\n",
    "sales_data['SKU_grouped']=sales_data['SKU Name'].str.split(',',expand=True)[0]\n",
    "sales_data['Order Date & Time']=pd.to_datetime(sales_data['Order Date & Time'])\n",
    "sales_data['Date']=sales_data['Order Date & Time'].dt.date\n",
    "sales_data_grouped=sales_data.groupby(['SKU_grouped','Date']).agg({'Quantity':'sum',\"Item Value\":\"sum\",\"Brand Name\":\"first\"}).reset_index()\n",
    "sales_data_grouped=sales_data_grouped.sort_values('Date') \n",
    "sales_data_grouped_select=sales_data.groupby(['SKU_grouped']).agg({'Quantity':'sum',\"Date\":'nunique'}).reset_index()\n",
    "\n",
    "sales_data_grouped_select=sales_data_grouped_select.rename(columns={'Quantity': 'Total Sales Value',\"Date\":'Date Count'})\n",
    "sales_data_grouped_select=sales_data_grouped_select.sort_values(by=['Date Count'],ascending=[False])\n",
    "sales_data_grouped_select=sales_data_grouped_select.head(20)\n",
    "\n",
    "sales_data_grouped_select=sales_data_grouped_select.merge(sales_data_grouped,on='SKU_grouped',how='left')\n",
    "sales_data_grouped_select.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data_grouped_select=sales_data_grouped_select.sort_values('Date')\n",
    "sales_data_grouped_select[\"SKU_grouped\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "start_date = datetime(2023, 1, 2)\n",
    "end_date = datetime(2025, 11, 30)\n",
    "\n",
    "# Generate daily dates\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Define Indian holidays including Dussehra and Black Friday\n",
    "indian_holidays = { \n",
    "    '2023-01-01': 'New Year',\n",
    "    '2023-01-26': 'Republic Day',\n",
    "    '2023-08-15': 'Independence Day',\n",
    "    '2023-10-24': 'Dussehra',\n",
    "    '2023-10-02': 'Gandhi Jayanti',\n",
    "    '2023-11-12': 'Diwali',\n",
    "    '2023-11-24': 'Black Friday',\n",
    "    '2023-12-25': 'Chrismas',\n",
    "    '2024-01-01': 'New Year',\n",
    "    '2024-01-26': 'Republic Day',\n",
    "    '2024-08-15': 'Independence Day',\n",
    "    '2024-10-13': 'Dussehra',\n",
    "    '2024-10-02': 'Gandhi Jayanti',\n",
    "    '2024-11-01': 'Diwali',\n",
    "    '2024-11-29': 'Black Friday',\n",
    "    '2024-12-25': 'Chrismas',\n",
    "    '2025-01-01': 'New Year',\n",
    "    '2025-01-26': 'Republic Day',\n",
    "    '2025-08-15': 'Independence Day',\n",
    "    '2025-10-02': 'Gandhi Jayanti',\n",
    "    '2025-10-02': 'Gandhi Jayanti',\n",
    "    '2025-10-21': 'Dussehra',\n",
    "    '2025-10-20': 'Diwali',\n",
    "    '2025-11-28': 'Black Friday', \n",
    "    '2025-12-25': 'Chrismas'\n",
    "}\n",
    "\n",
    "# Create a date_mapFrame\n",
    "date_map = pd.DataFrame({'Date': dates})\n",
    "\n",
    "# Add columns\n",
    "date_map['Year'] = date_map['Date'].dt.year                       # Extract year\n",
    "date_map['Month'] = date_map['Date'].dt.month  \n",
    "date_map['Day'] = date_map['Date'].dt.day    \n",
    "date_map['Week of Year'] = date_map['Date'].dt.isocalendar().week  # ISO week number\n",
    "#date_map['Week_Sequence'] = date_map['Year'].astype(str) +\"_\"+date_map['Week of Year'].astype(str)\n",
    "date_map['Month and Year'] = date_map['Year'].astype(str) +\"_\"+date_map['Month'].astype(str)\n",
    "month_and_year = date_map['Month and Year'].unique()\n",
    "date_map['Holiday Name'] = date_map['Date'].dt.strftime('%Y-%m-%d').map(indian_holidays)\n",
    "# Add a column to mark whether the date is a holiday or weekend\n",
    "#date_map['Is Weekend'] = np.where(date_map['Day of Week'].isin(['Saturday', 'Sunday']),1,0)\n",
    "date_map['Is Holiday'] = date_map['Holiday Name'].notna().astype(int) \n",
    "\n",
    "date_map['Week_Group'] = (date_map.index // 7) + 1\n",
    "\n",
    "#date_map=date_map.to_clipboard()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Add 14 days before festival\n",
    "#date_map['Date'] = pd.to_datetime(date_map['Date'])\n",
    "date_map['is_14_days_before_holiday']=0\n",
    "for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "    date_map.loc[\n",
    "        (date_map['Date']>=date - pd.Timedelta(days=14)) & (date_map['Date']<date),\n",
    "         'is_14_days_before_festival']=1 \n",
    "\n",
    "#Add a week before festival\n",
    "date_map['is_a_week_before_holiday']=0\n",
    "for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "    date_map.loc[\n",
    "        (date_map['Date']>=date - pd.Timedelta(days=14)) & (date_map['Date']<date -pd.Timedelta(days=7)),\n",
    "         'is_a_week_before_holiday']=1 \n",
    "\n",
    "#Add 7 days before festival\n",
    "date_map['is_7_days_before_holiday']=0\n",
    "for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "    date_map.loc[\n",
    "        (date_map['Date']>=date-pd.Timedelta(days=7)) & (date_map['Date']<date),\n",
    "         'is_7_days_before_festival']=1 \n",
    "date_map.to_clipboard()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_map['Week of Month'] = (date_map['Date'].dt.day-1) // 7 + 1\n",
    "prev_hold=0\n",
    "last_week_prevmonth=0\n",
    "adj_factor1=0\n",
    "final_df= pd.DataFrame()\n",
    "for month in month_and_year:\n",
    "    main_df=date_map[date_map['Month and Year']==month]\n",
    "    num_days = len(main_df)\n",
    "    num_week=(num_days-(7-prev_hold)) // 7+1\n",
    "    if prev_hold==0:\n",
    "        prev_hold_adj=7\n",
    "        adj_factor=1\n",
    "    else:\n",
    "        prev_hold_adj= prev_hold  \n",
    "        adj_factor=2\n",
    "    if prev_hold<=3 and prev_hold>0 :\n",
    "        Week_numtoimpute=1\n",
    "        adj_factor=2\n",
    "        adj_factor1=1\n",
    "        #adj_factor=1\n",
    "    elif prev_hold==0:\n",
    "        Week_numtoimpute=max_week\n",
    "        adj_factor=1\n",
    "        adj_factor1=0\n",
    "    else:    \n",
    "        Week_numtoimpute=max_week\n",
    "        adj_factor=1\n",
    "        adj_factor1=1\n",
    "    main_df['prevhold']=prev_hold   \n",
    "    main_df['test']=main_df['Day']-(7-prev_hold_adj+1) -1\n",
    "    main_df['test2']=7-prev_hold_adj+1 -1\n",
    "    last_day = main_df['Day'].max()\n",
    "    main_df['Week of month'] = main_df.apply(\n",
    "    lambda row: Week_numtoimpute if row['Day'] <= 7-prev_hold_adj+1  else (row['Day']-(7-prev_hold_adj+1) -1)//7+adj_factor ,axis=1)\n",
    "    remainder = (last_day-(7-prev_hold_adj)) % 7\n",
    "   \n",
    "    #print(last_day-remainder)\n",
    "    if remainder<=3 and remainder!=0:\n",
    "        last_week2impute=1\n",
    "    elif remainder==0:\n",
    "        last_week2impute=(last_day-(7-prev_hold_adj)) // 7+1\n",
    "    else:\n",
    "        last_week2impute=(last_day-(7-prev_hold_adj)) // 7+2\n",
    "\n",
    "     \n",
    "    main_df['Week of month'] = main_df.apply(\n",
    "    lambda row: row['Week of month'] if row['Day'] <= last_day-remainder+1 else last_week2impute ,axis=1)\n",
    "    \n",
    "    max_week = main_df['Week of month'].max()\n",
    "    prev_hold=remainder\n",
    "    if remainder==0:\n",
    "         prev_hold=7  \n",
    "         max_week = main_df['Week of month'].max()-1\n",
    "    main_df['rem']=remainder\n",
    "    final_df = pd.concat([final_df, main_df], ignore_index=True)\n",
    "        \n",
    "#Month_year_mod=final_df.groupby(['Year', 'Month','Week of Year','']).agg({'Day':'count' }).reset_index()    \n",
    "#Month_year_mod = Month_year_mod.sort_values(by='Day', ascending=True)\n",
    "#Month_year_mod = Month_year_mod.drop_duplicates(subset=['Year', 'Month', 'Week of Year'], keep='first') \n",
    "#final_df = final_df.drop(columns=['Year', 'Month', 'column3'])\n",
    "final_df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6658, 7)\n"
     ]
    }
   ],
   "source": [
    "#Merge festival data with SKU demand data\n",
    "unique_skus=sales_data_grouped_select['SKU_grouped'].unique()\n",
    "final_df=final_df[['Date',\"Year\",\"Month\",\"Week of Year\",'Is Holiday','is_14_days_before_festival','is_a_week_before_holiday','is_7_days_before_festival',\"Week of month\",'Day','Week_Group']]\n",
    "final_df['Date'] = pd.to_datetime(final_df['Date'])\n",
    "sales_data_grouped_select['Date'] = pd.to_datetime(sales_data_grouped_select['Date'])\n",
    "final_df1 = pd.DataFrame()\n",
    "for sku in  unique_skus:\n",
    "    main_df=sales_data_grouped_select[sales_data_grouped_select['SKU_grouped']==sku]\n",
    "    start_date=min(main_df['Date'])\n",
    "    end_date=max(main_df['Date'])\n",
    "    #print(start_date)\n",
    "    #print(end_date)\n",
    "    SKU_df = final_df[(final_df['Date'] >= start_date) & (final_df['Date'] <= end_date)]\n",
    "    SKU_df=SKU_df.merge(main_df,how='left',on='Date')\n",
    "    SKU_df['SKU_grouped'] = SKU_df['SKU_grouped'].fillna(method='ffill') \n",
    "    SKU_df['Quantity'] = SKU_df['Quantity'].fillna(0) \n",
    "    final_df1=pd.concat([final_df1, SKU_df], ignore_index=True)\n",
    "    \n",
    " #sales_data_grouped_select=   \n",
    "#sales_data_grouped_select=sales_data_grouped_select.merge(date_map[[\"Date\",\"Year\",\"Week of Year\",'Day of Year',\"Week of Month\",\"Is Weekend\",\"Is Holiday\"]],on='Date',how='left')\n",
    "# sales_data_grouped_select['is_festival']=sales_data_grouped_select['is_festival'].fillna(0).astype(int)\n",
    "print(sales_data_grouped_select.shape)\n",
    "sales_data_grouped_select=final_df1.copy()\n",
    "sales_data_grouped_select.to_clipboard()\n",
    "\n",
    "# Group by 'Category' and 'SubCategory' and sum only 'Value1' and 'Value2'\n",
    "result = sales_data_grouped_select.groupby(['Week of Year', 'Week of month','SKU_grouped','Week_Group']).agg({\n",
    "    'Is Holiday': 'sum',                     # Sum column C\n",
    "    'is_14_days_before_festival': 'sum', \n",
    "    'is_7_days_before_festival' : 'sum' ,                                 # Max value of column D\n",
    "    'is_a_week_before_holiday': 'sum', \n",
    "    'Quantity': 'sum' ,\n",
    "    'Day':'count',\n",
    "    'Year': lambda x: x.mode()[0],\n",
    "    'Month': lambda x: x.mode()[0] \n",
    "    }).reset_index()\n",
    "#result1 = sales_data_grouped_select.groupby(['Week of Year', 'Week of month','SKU_grouped','Year','count']).agg({\n",
    "#    'Day': 'count',\n",
    "#    }).reset_index()\n",
    "# Sorting by multiple columns\n",
    "#result = result.sort_values(by=[ 'Year','Week of Year'], ascending=[True, True])\n",
    "result.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by multiple columns\n",
    "result['Week_sin']=np.sin(2*np.pi*result['Week of Year']/52)   \n",
    "result['Week_cos']=np.cos(2*np.pi*result['Week of Year']/52)  \n",
    "result=result.sort_values(by=[ 'Week_Group'], ascending=[True])\n",
    "result['Lag_1']=result['Quantity'].shift(1)\n",
    "result['Lag_2']=result['Quantity'].shift(2)\n",
    "result['Lag_3']=result['Quantity'].shift(3)\n",
    "result['Moving_Avg_3']=result['Quantity'].rolling(window=3).mean()\n",
    "result['Moving_Avg_4']=result['Quantity'].rolling(window=4).mean()\n",
    "result['Moving_std_3']=result['Quantity'].rolling(window=3).std()\n",
    "result['Moving_std_4']=result['Quantity'].rolling(window=4).std()\n",
    "result = result[result['Day'] >= 7]\n",
    "result=result.dropna()\n",
    "result1=result.copy()\n",
    "#result.sort_values(by=[ 'Week_Group'], ascending=[True])\n",
    "result.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmape(y_true, y_pred):\n",
    "    if np.sum(y_true) == 0:\n",
    "        return 0\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(y_true)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# %pip install scikit-learn\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from prophet import Prophet\n",
    "# remove all warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# remove cmdstanpy warning for prophet\n",
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_forecast(train_df,test_df,forecasting_horizon,model_features):\n",
    "    print(\"Inside xgb_Model\")\n",
    "    param_grid={\"n_estimators\":[25,75,50,100,150],\n",
    "                \"learning_rate\":[0.01,0.05],\n",
    "                \"max_depth\":[3,5,4,7]}\n",
    "    train_data=train_df.copy()\n",
    "    test_data=test_df.copy()\n",
    "\n",
    "    Model_features=[str(col).replace(']','').replace('[','').replace('<','').replace('>','') for col in model_features]\n",
    "    wmape_scorer=make_scorer(wmape,greater_is_better=False)\n",
    "    model=XGBRegressor(objective='reg:squarederror')\n",
    "    X_train=train_data[Model_features]\n",
    "    y_train=train_data['Quantity']\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # Use gridsearchCV for hyperparameter tuning\n",
    "    grid_search=GridSearchCV(model,param_grid=param_grid,scoring=wmape_scorer,cv=5)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model=grid_search.best_estimator_\n",
    "    best_model.fit(X_train,y_train)\n",
    "    train_predictions=best_model.predict(X_train)\n",
    "    test_predictions=best_model.predict(test_data[Model_features])\n",
    "\n",
    "    train_wmape=wmape(y_train,train_predictions)\n",
    "    test_wmape=wmape(test_data['Quantity'],test_predictions)\n",
    "\n",
    "    train_data['Prediction']=train_predictions\n",
    "    test_data['Prediction']=test_predictions\n",
    "\n",
    "    combined_data=pd.concat([train_data,test_data],axis=0)\n",
    "    return combined_data[[\"SKU_grouped\",\"Week_Group\",\"Quantity\",\"Prediction\"]],train_wmape,test_wmape,best_model\n",
    "\n",
    "params_grid={\n",
    "            \"seasonality_mode\":(\"multiplicative\",\"additive\"),\n",
    "            \"changepoint_prior_scale\":[0.1,0.3,0.5,0.7],\n",
    "            \"seasonality_prior_scale\":[1.0,5.0,10.0],\n",
    "            \"n_changepoints\":[25,35,50]\n",
    "\n",
    "}\n",
    "grid= ParameterGrid(params_grid)\n",
    "\n",
    "\n",
    "def multivariate_prophet(train_df, test_df, forecasting_horizon, model_features):\n",
    "    print(\"Inside multivariate_prophet\")\n",
    "    model_parameters=pd.DataFrame(columns=[\"WMAPE\",\"Parameters\"])\n",
    "    train_data=train_df.copy()\n",
    "    test_data=test_df.copy()\n",
    "    train_data=train_data.rename(columns={\"Date\":\"ds\",\"Quantity\":\"y\"})\n",
    "    test_data=test_data.rename(columns={\"Date\":\"ds\",\"Quantity\":\"y\"})\n",
    "    Model_features=[str(col).replace(']','').replace('[','').replace('<','').replace('>','') for col in model_features]\n",
    "    for p in grid:\n",
    "        prophet_model=Prophet(changepoint_prior_scale = p[\"changepoint_prior_scale\"],\n",
    "                              n_changepoints=p[\"n_changepoints\"],\n",
    "                                seasonality_mode=p[\"seasonality_mode\"],\n",
    "                                seasonality_prior_scale=p[\"seasonality_prior_scale\"])\n",
    "        \n",
    "        for reg in model_features:\n",
    "            prophet_model.add_regressor(reg)\n",
    "\n",
    "        prophet_model.add_country_holidays(country_name='IN')\n",
    "        prophet_model.fit(train_data)\n",
    "        future_dates=pd.date_range(start=train_df[\"Date\"].max()+timedelta(days=1),periods=30,freq='D')\n",
    "        future = pd.DataFrame({\"ds\": future_dates})\n",
    "        for col in model_features:\n",
    "            future[col] = test_df[col].values\n",
    "\n",
    "        prophet_forecast=prophet_model.predict(future)\n",
    "        test_predictions = prophet_forecast.loc[prophet_forecast['ds'].isin(test_df['Date'])]['yhat']\n",
    "\n",
    "        WMAPE = wmape(test_df['Quantity'], test_predictions.values)\n",
    "\n",
    "        x=pd.DataFrame({\"WMAPE\":WMAPE,\"Parameters\":[p]})\n",
    "        model_parameters=pd.concat([model_parameters,x],ignore_index=False)\n",
    "\n",
    "    params = model_parameters[model_parameters['WMAPE']==model_parameters['WMAPE'].min()]['Parameters'].values[0]\n",
    "\n",
    "    model = Prophet(changepoint_prior_scale = params[\"changepoint_prior_scale\"],\n",
    "                    n_changepoints=params[\"n_changepoints\"],\n",
    "                    seasonality_mode=params[\"seasonality_mode\"],\n",
    "                    seasonality_prior_scale=params[\"seasonality_prior_scale\"],\n",
    "                    interval_width=0.95)\n",
    "    for col in model_features:\n",
    "        model.add_regressor(col)\n",
    "\n",
    "    model.fit(train_data)\n",
    "\n",
    "    future = model.make_future_dataframe(periods=30, freq='D')\n",
    "    for col in model_features:\n",
    "        future[col] = pd.concat([train_df,test_df])[col].values\n",
    "    forecast = model.predict(future)\n",
    "    train_wmape = wmape(train_data['y'], model.predict(train_data)['yhat'])\n",
    "    test_wmape = wmape(test_data['y'], forecast[\"yhat\"].tail(forecasting_horizon))\n",
    "    train_data['Prediction'] = model.predict(train_data)['yhat'].values\n",
    "    train_data[\"Set\"]=\"Train\"\n",
    "\n",
    "    test_data['Prediction']=forecast[\"yhat\"].tail(forecasting_horizon).values\n",
    "    test_data[\"Set\"]=\"Test\"\n",
    "\n",
    "    combined_data=pd.concat([train_data,test_data],axis=0)\n",
    "    combined_data['SKU_grouped']=sku\n",
    "    combined_data.rename(columns={\"ds\":\"Date\",\"y\":\"Quantity\"},inplace=True)\n",
    "    return combined_data[[\"SKU_grouped\",\"Date\",\"Quantity\",\"Prediction\"]],train_wmape,test_wmape,model\n",
    "\n",
    "def multi_prophet_forecasting(main_df, test_df, prophet_model, model_features, forecasting_horizon=60):\n",
    "    print(\"Inside multi_prophet_forecasting\")\n",
    "    future_dates=pd.date_range(start=test_df[\"Date\"].max()+timedelta(days=1),periods=forecasting_horizon,freq='D')\n",
    "    future=pd.DataFrame({\"ds\":future_dates})\n",
    "    future['Year'] = future['ds'].dt.year                       # Extract year\n",
    "    future['Week of Year'] = future['ds'].dt.isocalendar().week  # ISO week number\n",
    "    # add week of month also\n",
    "    future['Week of Month'] = (future['ds'].dt.day-1) // 7 + 1\n",
    "    # Add Is Weekend flag\n",
    "    future['Day of Week'] = future['ds'].dt.day_name()          # Day name (e.g., Sunday, Monday)\n",
    "\n",
    "    # add day of Year\n",
    "    future['Day of Year'] = future['ds'].dt.dayofyear\n",
    "    future['Week Ending Date'] = future['ds'] + pd.offsets.Week(weekday=5)  # Saturday as week-ending date\n",
    "    # Add holiday names\n",
    "    future['Holiday Name'] = future['ds'].dt.strftime('%Y-%m-%d').map(indian_holidays)\n",
    "    # Add a column to mark whether the date is a holiday or weekend\n",
    "    future['Is Weekend'] = np.where(future['Day of Week'].isin(['Saturday', 'Sunday']),1,0)\n",
    "    future['Is Holiday'] = future['Holiday Name'].notna().astype(int)\n",
    "    future['is_14_days_before_holiday']=0\n",
    "    for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "        future.loc[\n",
    "            (future['ds']>=date - pd.Timedelta(days=14)) & (future['ds']<date),\n",
    "            'is_14_days_before_festival']=1\n",
    "    future['is_7_days_before_holiday']=0\n",
    "    for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "        future.loc[\n",
    "            (future['ds']>=date-pd.Timedelta(days=7)) & (future['ds']<date),\n",
    "            'is_7_days_before_festival']=1\n",
    "    date_map\n",
    "    # add demand lag 7 by taking values from last year and merging it by week of year\n",
    "    future=future.merge(main_df[['Day of Year','demand_lag_7','demand_lag_1','demand_lag_14','rolling mean 7','rolling std 7']].drop_duplicates(),on=['Day of Year'],how='left')\n",
    "    future['day of week']=future['ds'].dt.dayofweek\n",
    "    future['day of month']=future['ds'].dt.month\n",
    "    future.fillna(0,inplace=True)\n",
    "    future['Week of Year'] = future['Week of Year'].astype(int)\n",
    "    future['Prediction']=prophet_model.predict(future)[\"yhat\"]\n",
    "    future[\"Quantity\"]=np.nan\n",
    "    future['SKU_grouped']=sku\n",
    "    future['Date']=future['ds']\n",
    "    return future[[\"SKU_grouped\",\"Date\",\"Prediction\"]]\n",
    "\n",
    "\n",
    "def xgb_forecaster(main_df,test_df, xgb_model, model_features, forecasting_horizon=1):   \n",
    "    print(\"Inside xgb_forecaster\") \n",
    "    start=test_df[\"Week_Group\"].max()+1\n",
    "    future=pd.DataFrame({\"Date\":future_dates})\n",
    "\n",
    "    future['Year'] = future['Date'].dt.year                       # Extract year\n",
    "    future['Week of Year'] = future['Date'].dt.isocalendar().week  # ISO week number\n",
    "    # add week of month also\n",
    "    future['Week of Month'] = (future['Date'].dt.day-1) // 7 + 1\n",
    "    # Add Is Weekend flag\n",
    "    future['Day of Week'] = future['Date'].dt.day_name()          # Day name (e.g., Sunday, Monday)\n",
    "    # add day of Year\n",
    "    future['Day of Year'] = future['Date'].dt.dayofyear\n",
    "    future['Week Ending Date'] = future['Date'] + pd.offsets.Week(weekday=5)  # Saturday as week-ending date\n",
    "    # Add holiday names\n",
    "    future['Holiday Name'] = future['Date'].dt.strftime('%Y-%m-%d').map(indian_holidays)\n",
    "    # Add a column to mark whether the date is a holiday or weekend\n",
    "    future['Is Weekend'] = np.where(future['Day of Week'].isin(['Saturday', 'Sunday']),1,0)\n",
    "    future['Is Holiday'] = future['Holiday Name'].notna().astype(int)\n",
    "    future['is_14_days_before_holiday']=0\n",
    "    for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "        future.loc[\n",
    "            (future['Date']>=date - pd.Timedelta(days=14)) & (future['Date']<date),\n",
    "            'is_14_days_before_festival']=1\n",
    "    future['is_7_days_before_holiday']=0\n",
    "    for date in date_map[date_map['Is Holiday']==1][\"Date\"].unique():\n",
    "        future.loc[\n",
    "            (future['Date']>=date-pd.Timedelta(days=7)) & (future['Date']<date),\n",
    "            'is_7_days_before_festival']=1\n",
    "\n",
    "    # add demand lag 7 by taking values from last year and merging it by week of year\n",
    "    future=future.merge(main_df[['Day of Year','demand_lag_7','demand_lag_1','demand_lag_14','rolling mean 7','rolling std 7']].drop_duplicates(),on=['Day of Year'],how='left')\n",
    "\n",
    "\n",
    "    future['day of week']=future['Date'].dt.dayofweek\n",
    "    future['day of month']=future['Date'].dt.month\n",
    "    future.fillna(0,inplace=True)\n",
    "    future['Prediction']=xgb_model.predict(future[model_features])\n",
    "    future[\"Quantity\"]=np.nan\n",
    "    future['SKU_grouped']=sku\n",
    "    return future\n",
    "    #return future[[\"SKU_grouped\",\"Date\",\"Prediction\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting for SKU:MuscleBlaze Biozyme Performance Whey\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Biozyme Performance Whey:0.0025883899468606324 (train) and 0.09848528764745053 (test)\n",
      "Forecasting for SKU:MuscleBlaze Chocolate Peanut Butter\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Chocolate Peanut Butter:0.01218687961249024 (train) and 0.5223667287380895 (test)\n",
      "Forecasting for SKU:MuscleBlaze 80% Raw Whey Protein Supplement Powder\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze 80% Raw Whey Protein Supplement Powder:0.17234792535955257 (train) and 0.6270174425701762 (test)\n",
      "Forecasting for SKU:MuscleBlaze MB-VITE Daily Multivitamin\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze MB-VITE Daily Multivitamin:0.1527226126565474 (train) and 0.391455534732703 (test)\n",
      "Forecasting for SKU:MB Fuel One Whey Protein\n",
      "Inside xgb_Model\n",
      "WMAPE for MB Fuel One Whey Protein:0.24403741948173854 (train) and 0.3712436252170139 (test)\n",
      "Forecasting for SKU:MuscleBlaze High Protein Muesli\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze High Protein Muesli:0.05133635761681295 (train) and 0.3452674018012153 (test)\n",
      "Forecasting for SKU:HealthKart HK Vitals Biotin\n",
      "Inside xgb_Model\n",
      "WMAPE for HealthKart HK Vitals Biotin:0.22938460059267665 (train) and 0.11672689748364826 (test)\n",
      "Forecasting for SKU:HealthKart HK Vitals Fish Oil 1000mg with 180mg EPA and 120mg DHA\n",
      "Inside xgb_Model\n",
      "WMAPE for HealthKart HK Vitals Fish Oil 1000mg with 180mg EPA and 120mg DHA:0.06872036883265463 (train) and 0.37460000804393967 (test)\n",
      "Forecasting for SKU:MuscleBlaze Pre Workout WrathX\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Pre Workout WrathX:0.16670092187746607 (train) and 0.2096871024683902 (test)\n",
      "Forecasting for SKU:MuscleBlaze High Protein Peanut Butter\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze High Protein Peanut Butter:0.08067207427128502 (train) and 0.3462773997609208 (test)\n",
      "Forecasting for SKU:HealthKart HK Vitals Multivitamin with Multimineral\n",
      "Inside xgb_Model\n",
      "WMAPE for HealthKart HK Vitals Multivitamin with Multimineral:0.02848683181383931 (train) and 0.24664598603488347 (test)\n",
      "Forecasting for SKU:MuscleBlaze Omega 3 Fish Oil (1000 mg) with 180mg EPA and 120mg DHA\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Omega 3 Fish Oil (1000 mg) with 180mg EPA and 120mg DHA:0.009113794764096822 (train) and 0.19826247375135478 (test)\n",
      "Forecasting for SKU:HK Vitals Skin Radiance Collagen by HealthKart\n",
      "Inside xgb_Model\n",
      "WMAPE for HK Vitals Skin Radiance Collagen by HealthKart:0.004825977743678869 (train) and 0.1820623591794806 (test)\n",
      "Forecasting for SKU:HealthKart HK Vitals Skin Radiance Collagen\n",
      "Inside xgb_Model\n",
      "WMAPE for HealthKart HK Vitals Skin Radiance Collagen:0.003837867305703359 (train) and 0.5957799620975722 (test)\n",
      "Forecasting for SKU:MuscleBlaze Liquid L-Carnitine\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Liquid L-Carnitine:0.00625411341013002 (train) and 0.20789738190479767 (test)\n",
      "Forecasting for SKU:MuscleBlaze High Protein Oats\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze High Protein Oats:0.02116090589280657 (train) and 0.24414155089739456 (test)\n",
      "Forecasting for SKU:MuscleBlaze PRE Workout 200 Xtreme\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze PRE Workout 200 Xtreme:0.14079590824837043 (train) and 0.15205277473695816 (test)\n",
      "Forecasting for SKU:MuscleBlaze Super Gainer XXL Weight Gainer\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze Super Gainer XXL Weight Gainer:0.03892974351030804 (train) and 0.2975906093468827 (test)\n",
      "Forecasting for SKU:MuscleBlaze CreaPRO Creatine with CreapureÂ® Powder from Germany\n",
      "Inside xgb_Model\n",
      "WMAPE for MuscleBlaze CreaPRO Creatine with CreapureÂ® Powder from Germany:0.18764950378596434 (train) and 0.10385676792689733 (test)\n",
      "Forecasting for SKU:Fuel One Whey Max\n",
      "Inside xgb_Model\n",
      "WMAPE for Fuel One Whey Max:0.4264896416225316 (train) and 0.3628714796136187 (test)\n"
     ]
    }
   ],
   "source": [
    "forecast_df=pd.DataFrame()\n",
    "\n",
    "results=pd.DataFrame(columns=['SKU','Model','Train WMAPE','Test WMAPE'])\n",
    "for sku in unique_skus:\n",
    "    print(f'Forecasting for SKU:{sku}')\n",
    "    \n",
    "    main_df=result1[result1['SKU_grouped']==sku]\n",
    "    \n",
    "    max_date=main_df['Week_Group'].max()\n",
    "    max_train_date=main_df['Week_Group'].max()-3\n",
    "    main_df['Week of Year'] = main_df['Week of Year'].astype(int)\n",
    "    train_df=main_df[main_df['Week_Group']<=max_train_date]\n",
    "    test_df=main_df[main_df['Week_Group']>max_train_date]\n",
    "\n",
    "    model_features=[\"Year\",'Week of Year', 'Week of month', 'Is Holiday', 'is_14_days_before_festival', 'is_7_days_before_festival', 'is_a_week_before_holiday',\n",
    "       'Month', 'Week_sin', 'Week_cos', 'Lag_1','Lag_2','Lag_3',\t'Moving_Avg_3','Moving_Avg_4','Moving_std_3','Moving_std_4']\n",
    "    combined_data_xgb,train_wmape,test_wmape,xgb_model=xgb_forecast(train_df,test_df,3,model_features)\n",
    "    future=xgb_forecaster(main_df,test_df,xgb_model,model_features,1)\n",
    "    results.loc[len(results)] = [sku, \"XGBoost\", train_wmape, test_wmape]\n",
    "    #sku_df_xgb=combined_data_xgb.copy()\n",
    "    sku_df_xgb=pd.concat([combined_data_xgb,future])\n",
    "    sku_df_xgb[\"Train_wmape\"]=train_wmape\n",
    "    sku_df_xgb[\"Test_wmape\"]=test_wmape\n",
    "    sku_df_xgb[\"Model\"]=\"XGBoost\"\n",
    "    print(f'WMAPE for {sku}:{train_wmape} (train) and {test_wmape} (test)')\n",
    "    #combined_data_prophet,train_wmape,test_wmape,prophet_model=multivariate_prophet(train_df,test_df,30,model_features)\n",
    "    #future=multi_prophet_forecasting(main_df,test_df,prophet_model,model_features,60)\n",
    "    #results.loc[len(results)] = [sku, \"Prophet\", train_wmape, test_wmape]\n",
    "    #sku_df=pd.concat([combined_data_prophet,future])\n",
    "    #sku_df[\"Train_wmape\"]=train_wmape\n",
    "    #sku_df[\"Test_wmape\"]=test_wmape\n",
    "    #sku_df[\"Model\"]=\"Prophet\"\n",
    "    #print(f'WMAPE for {sku}:{train_wmape} (train) and {test_wmape} (test)')\n",
    "    forecast_df=pd.concat([forecast_df,sku_df_xgb],axis=0)\n",
    "    #forecast_df=pd.concat([forecast_df,sku_df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_clipboard() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
